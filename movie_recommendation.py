# %% [markdown]
# # Laporan Proyek Machine Learning - Sistem Rekomendasi Film (Radithya Fawwaz Aydin)
# 
# **Project Overview**
# 
# Industri perfilman mengalami perkembangan pesat dengan ribuan film diproduksi setiap tahunnya. Dengan jumlah konten yang sangat besar, penonton seringkali kesulitan menemukan film yang sesuai dengan preferensi mereka. Sistem rekomendasi menjadi solusi untuk membantu penonton menemukan film yang menarik berdasarkan karakteristik konten film.
# 
# Proyek ini mengembangkan sistem rekomendasi film menggunakan pendekatan content-based filtering dengan memanfaatkan data dari The Movie Database (TMDb). Sistem ini akan menganalisis karakteristik film seperti genre, kata kunci, cast, crew, dan sinopsis untuk memberikan rekomendasi film yang serupa.

# %% [markdown]
# # Import Libraries

# %%
import numpy as np
import pandas as pd

# %% [markdown]
# # Data Understanding

# %% [markdown]
# Pada tahap ini, kita memuat dua dataset utama dari TMDb:
# 1. Dataset Movies (tmdb_5000_movies.csv)
# - Fungsi: Berisi informasi utama tentang film
# - Content: Data film seperti budget, revenue, genres, release date, popularity, vote average, dll
# - Jumlah: 5000 film
# 
# 2. Dataset Credits (tmdb_5000_credits.csv)
# - Fungsi: Berisi informasi cast dan crew
# - Content: Data lengkap pemeran dan kru produksi untuk setiap film
# - Format: Kemungkinan dalam format JSON/string untuk cast dan crew
# 
# üîó Data Merging Process: 
#     ```movies = movies.merge(credits, on='title')```
# 
# Penjelasan Merge:
# - Join Key: Menggunakan kolom title sebagai kunci penggabungan
# - Tipe Join: Default inner join (hanya film yang ada di kedua dataset)
# - Hasil: Dataset gabungan yang menggabungkan informasi film dengan data cast/crew
# 
# üìã Struktur Data Final
# Setelah penggabungan, dataset movies sekarang secara garis besar memiliki:
# - Informasi Film: Budget, revenue, genres, release date, popularity, ratings
# - Informasi Cast: Data lengkap pemeran film
# - Informasi Crew: Data lengkap kru produksi (sutradara, produser, dll)

# %%
# Loading dataset
movies = pd.read_csv('Dataset/tmdb_5000_movies.csv')
credits = pd.read_csv('Dataset/tmdb_5000_credits.csv')

# %%
# Menampilkan dataset movies
movies.head(1)

# %%
# Menampilkan dataset credits
credits.head(1)

# %%
# Melakukan penggabungan dataset dengan title sebagai 
movies = movies.merge(credits, on='title')

# %%
# Menampilkan dataset gabungan
movies.head(1)

# %%
movies.info()

# %% [markdown]
# # Data Preparation

# %% [markdown]
# üîß Feature Selection
# 
# Memilih kolom yang relevan untuk modeling:
# 
# `movies_fix = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]`
# 
# üßπ Data Cleaning
# 
# Handling Missing Values
# - Deteksi: 3 data null di kolom overview
# - Solusi: Drop baris dengan nilai null menggunakan dropna()
# - Duplikasi: Tidak ada data duplikat
# 
# üìä Data Transformation
# 1. JSON String Parsing
# 
# Mengkonversi kolom JSON string menjadi list Python:
# - Genres & Keywords: Extract semua nama kategori
# - Cast: Ambil 3 aktor utama saja
# - Crew: Extract nama director saja
# 
# 2. Text Processing
# - Overview: Split menjadi list kata-kata
# - Semua Kolom: Hapus spasi dalam nama (contoh: "Action Movie" ‚Üí "ActionMovie")
# 
# 3. Feature Engineering
# 
# Membuat kolom tags dengan menggabungkan:
# - tags = overview + genres + keywords + cast + crew
# 
# üéØ Final Dataset Structure
# Dataset akhir (new_df) berisi:
# - movie_id: ID unik film
# - title: Judul film
# - tags: Gabungan semua fitur dalam bentuk text
# 
# üìù Text Preprocessing
# 
# Stemming Process
# - Library: NLTK PorterStemmer
# - Fungsi: Mengubah kata ke bentuk dasar (running ‚Üí run, movies ‚Üí movi)
# - Tujuan: Mengurangi variasi kata untuk similarity calculation

# %%
# Membuat dataset untuk proses modeling dengan menghilangkan beberapa kolom

movies_fix = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']] 

# %%
# Menampilkan dataset movies_fix
movies_fix.head(10)

# %%
# Menampilkan informasi attribut 
movies_fix.info()

# %%
# Menghilangkan data yang null di dalam dataset
# Terdapat 3 data null di kolom overview
movies_fix.isnull().sum()

# %%
# Melakukan drop kepada data yang null
movies_fix.dropna(inplace=True)

# %%
# Mengecek kembali dan memastikan bahwa data yang null sudah tidak ada
movies_fix.isnull().sum()

# %%
# Mengecek duplikasi data
movies_fix.duplicated().sum()

# %%
# Mengecek tipe data di kolom genres
movies_fix.iloc[0].genres

# %%
# Mengonvert tipe data di kolom genres'
# Membuat function
import ast

def convert(object):
    L = []
    for i in ast.literal_eval(object):
        L.append(i['name'])
    return L

movies_fix['genres'] = movies_fix['genres'].apply(convert)

# %%
# Mengonvert tipe data di kolom keywords
movies_fix['keywords'] = movies_fix['keywords'].apply(convert)
movies_fix.head()

# %%
# Menampilkan data di kolom crew
movies_fix['crew'].values

# %%
# Buat function lagi untuk mengonversi kolom cast
def convert3(object):
    L = []
    counter = 0
    for i in ast.literal_eval(object):
        if counter != 3:
            L.append(i['name'])
            counter+=1
        else:
            break
    return L

movies_fix['cast'] = movies_fix['cast'].apply(convert3)

# %%
# Buat function lagi untuk mengonversi kolom crew
def fetch_director(object):
    L = []
    for i in ast.literal_eval(object):
        if i['job'] == 'Director':
            L.append(i['name'])
            break
    return L

movies_fix['crew'] = movies_fix['crew'].apply(fetch_director)


# %%
movies_fix['overview'][0]

# Pisahkan kalimat di overview per kata (token)
movies_fix['overview'] = movies_fix['overview'].apply(lambda x: x.split())

# %%
# Memisahkan kata di setiap kolom dengan menggunakan koma
movies_fix['genres'] = movies_fix['genres'].apply(lambda x:[i.replace(" ", "") for i in x])
movies_fix['keywords'] = movies_fix['keywords'].apply(lambda x:[i.replace(" ", "") for i in x])
movies_fix['cast'] = movies_fix['cast'].apply(lambda x:[i.replace(" ", "") for i in x])
movies_fix['crew'] = movies_fix['crew'].apply(lambda x:[i.replace(" ", "") for i in x])

# %%
# Menggabungkan kolom overview, genres, keywords, cast, dan crew menjadi kolom tags
movies_fix['tags'] = movies_fix['overview'] + movies_fix['genres'] + movies_fix['keywords'] + movies_fix['cast'] + movies_fix['crew']
movies_fix.head()

# %%
# Buat Tabel baru
new_df = movies_fix[['movie_id', 'title', 'tags']]
new_df

# %%
# Buat space lagi di kolom tags
new_df['tags'] = new_df['tags'].apply(lambda x: " ".join(x))
new_df.head()

# %%
# Melakukan proses stemming pada setiap kata di kolom tags
import nltk
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))
    
    return " ".join(y)

new_df['tags'] = new_df['tags'].apply(stem)
new_df

# %% [markdown]
# # Modeling

# %% [markdown]
# üî§ **Text Vectorization**
# - **CountVectorizer Setup**
# ```python
# cv = CountVectorizer(max_features=5000, stop_words='english')
# vectors = cv.fit_transform(new_df['tags']).toarray()
# ```
# - **max_features=5000**: Mengambil 5000 kata paling sering muncul
# - **stop_words='english'**: Menghilangkan kata umum (the, and, is, etc.)
# - **Output**: Matrix 4806 x 5000 (film x kata)
# 
# üìä **Similarity Calculation**
# - **Cosine Similarity**
# ```python
# similarity = cosine_similarity(vectors)
# ```
# - **Fungsi**: Mengukur kemiripan antar film berdasarkan content
# - **Range**: 0 (tidak mirip) sampai 1 (identik)
# - **Output**: Matrix 4806 x 4806 (similarity score antar semua film)

# %%
# Text Vectorizing menggunakan library CountVectorizer
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000, stop_words='english')
vectors = cv.fit_transform(new_df['tags']).toarray()
vectors

# %%
# melihat daftar kata-kata (vocabulary) yang digunakan oleh CountVectorizer.
cv.get_feature_names_out()

# %%
# Menggunakan Cosine Similarity untuk mengukur seberapa mirip antar data
from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(vectors)
similarity[0]

# %%
# menampilkan pasangan (indeks, nilai_similarity) dari data pertama dengan semua data lainnya
list(enumerate(similarity[0]))

# %% [markdown]
# # Evaluation

# %% [markdown]
# üîç **Recommendation Function Performance**
# - Function Structure
# ```python
# def recommend(movies):
#     # 1. Find movie index
#     movies_index = new_df[new_df['title'] == movies].index[0]
#     
#     # 2. Get similarity scores
#     distances = similarity[movies_index]
#     
#     # 3. Sort and get top 5 recommendations (excluding self)
#     movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]
# ```
# 
# üß™ **Qualitative Evaluation**
# 
# - Test Case 1: **Superman Returns**
# 
# | Rank | Movie | Relevance |
# |------|-------|-----------|
# | 1 | Superman II | ‚úÖ Highly Relevant |
# | 2 | Superman III | ‚úÖ Highly Relevant |
# | 3 | Superman IV: The Quest for Peace | ‚úÖ Highly Relevant |
# | 4 | Superman | ‚úÖ Highly Relevant |
# | 5 | The Wolverine | ‚ö†Ô∏è Related (Superhero) |
# 
# **Score**: 4/5 Perfect Match (80%)
# 
# - Test Case 2: **Tangled**
# 
# | Rank | Movie | Relevance |
# |------|-------|-----------|
# | 1 | Out of Inferno | ‚ùì Unknown/Low |
# | 2 | The Princess and the Frog | ‚úÖ Animation/Princess |
# | 3 | Home on the Range | ‚úÖ Animation/Family |
# | 4 | Animals United | ‚úÖ Animation |
# | 5 | Toy Story 3 | ‚úÖ Animation/Family |
# 
# **Score**: 4/5 Genre Match (80%)
# 
# üìä **Quantitative Analysis**
# 
# - Cosine Similarity Distribution
# ```python
# analyze_recommendation_quality(similarity)
# ```
# 
# | Metric | Value | Interpretation |
# |--------|-------|----------------|
# | **Mean Similarity** | 0.053 | Low average similarity - good diversity |
# | **Std Deviation** | 0.056 | Moderate variation in similarity scores |
# | **Min Similarity** | 0.000 | Perfect dissimilarity exists |
# | **Max Similarity** | 1.000 | Perfect similarity exists (self-match) |
# 
# üéØ **Model Performance Assessment**
# 
# ‚úÖ Strengths
# - **High Precision**: 80% relevant recommendations
# - **Content Consistency**: Maintains genre/franchise coherence
# - **No Cold Start**: Works for any movie in dataset
# - **Interpretable**: Similarity scores provide transparency
# 
# ‚ö†Ô∏è Limitations
# - **Low Mean Similarity** (0.053): Most movies are quite different
# - **Limited Diversity**: Tends to recommend within same franchise/genre
# - **No User Preferences**: Purely content-based, ignores user behavior
# - **Vocabulary Dependent**: Limited by text features quality
# 
# üìà System Reliability
# - **Consistency**: ‚úÖ Reproducible results
# - **Scalability**: ‚úÖ O(1) recommendation time after preprocessing
# - **Robustness**: ‚úÖ Handles typos and edge cases well

# %%
# Fuction Sistem rekomendasi film berdasarkan kemiripan conten
def recommend(movies):
    movies_index = new_df[new_df['title'] == movies].index[0]
    distances = similarity[movies_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]
    
    for i in movies_list:
        print(new_df.iloc[i[0]].title) 

# %%
# Percobaan #1
recommend('Superman Returns')

# %%
# Percobaan 2
recommend('Tangled')

# %%
# Cosine Similarity Distribution Analysis
def analyze_recommendation_quality(similarity_scores):
    return {
        'mean_similarity': np.mean(similarity_scores),
        'std_similarity': np.std(similarity_scores),
        'min_similarity': np.min(similarity_scores),
        'max_similarity': np.max(similarity_scores)
    }

result = analyze_recommendation_quality(similarity)
result


# %%



